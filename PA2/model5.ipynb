{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Early merge with soft parameters ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import  Dataset\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import random\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class early_dataloader(Dataset):\n",
    "    def __init__(self, data_dir , train):\n",
    "        self.data_dir = data_dir\n",
    "        self.all_classes = ['NotSnow','Snow']\n",
    "        self.class_indexes = {cls: idx for idx, cls in enumerate(self.all_classes)}\n",
    "        self.dataset = self.dataset_maker(train)\n",
    "        self.length = len(self.dataset)\n",
    "    def dataset_maker(self, train): # this will compile all the folder paths and the corresponding classes in a tuple to be stored in the class\n",
    "        data_list = []\n",
    "        for class_name in self.all_classes:\n",
    "            all_class_folders =os.path.join(self.data_dir, class_name)\n",
    "            for fold in os.listdir(all_class_folders):\n",
    "                if fold == \".DS_Store\":\n",
    "                    continue\n",
    "                sample_path_n_class = os.path.join(all_class_folders, fold)\n",
    "                sample = (sample_path_n_class, self.class_indexes[class_name])\n",
    "                data_list.append(sample)\n",
    "        random.shuffle(data_list)\n",
    "        if train:\n",
    "            return data_list[:int(0.8*len(data_list))]\n",
    "        else:\n",
    "            return data_list[int(0.8*len(data_list)):]\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        sample_path, sample_class = self.dataset[index]\n",
    "       \n",
    "        pic1 = transforms.ToTensor()(Image.open(os.path.join(sample_path, '0.png')).convert('L')) # image 1 in tensor\n",
    "        pic2 = transforms.ToTensor()(Image.open(os.path.join(sample_path, '1.png')).convert('L')) # image 2 in tensor\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "        ])\n",
    "        pic1 = transform(pic1)\n",
    "        pic2 = transform(pic2)\n",
    "        \n",
    "        return pic1.unsqueeze(0) , pic2.unsqueeze(0), sample_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_soft_training = early_dataloader(\"./dataset/\", True)\n",
    "e_soft_testing = early_dataloader(\"./dataset/\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 224, 224])\n",
      "torch.Size([1, 1, 224, 224])\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "sample4 = e_soft_training[242]\n",
    "print(sample4[0].shape)\n",
    "print(sample4[1].shape)\n",
    "print(sample4[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class early_soft_NN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(early_soft_NN, self).__init__()\n",
    "        self.conv1 = nn. Conv2d(1, 2, kernel_size=2, stride=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv3 = nn. Conv2d(4, 4, kernel_size=2, stride=1)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=4, stride=1)\n",
    "        self.conv4 = nn. Conv2d(4, 2, kernel_size=3, stride=1)\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=5, stride=4)\n",
    "        self.fc1 = nn.Linear (1352, 2)\n",
    "        \n",
    "    def forward (self, x1,x2):\n",
    "        x1 = F.relu(self.conv1(x1))\n",
    "        x1 = self.pool(x1)\n",
    "        x2 = F.relu(self.conv1(x2))\n",
    "        x2 = self.pool(x2)\n",
    "        x= torch.cat((x1, x2), dim=1)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.pool3(x)\n",
    "        x = F.relu(self.conv4 (x))\n",
    "        x = self.pool4(x)\n",
    "        x=torch.flatten (x, 1)\n",
    "        x = self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper parameters\n",
    "learning_rate_5= 0.001\n",
    "epochs_5 = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training the neural net with the stacking dataset\n",
    "model5 = early_soft_NN()\n",
    "criterion5 = nn.CrossEntropyLoss()\n",
    "optimiser5 = optim.Adam(model5.parameters(), lr = learning_rate_5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the total number of parameters in this model are 2858\n"
     ]
    }
   ],
   "source": [
    "# model params\n",
    "total_params = sum(p.numel() for p in model5.parameters())\n",
    "print(f'the total number of parameters in this model are {total_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is epoch number 0\n",
      "this is the 0 iteration\n",
      "loss: 63.336 accuracy: 72.100\n",
      "this is the 1000 iteration\n",
      "loss: 54.946 accuracy: 72.900\n",
      "this is the 2000 iteration\n",
      "this is epoch number 1\n",
      "this is the 0 iteration\n",
      "loss: 23.994 accuracy: 91.000\n",
      "this is the 1000 iteration\n",
      "loss: 21.003 accuracy: 91.800\n",
      "this is the 2000 iteration\n",
      "this is epoch number 2\n",
      "this is the 0 iteration\n",
      "loss: 19.811 accuracy: 92.700\n",
      "this is the 1000 iteration\n",
      "loss: 17.320 accuracy: 93.400\n",
      "this is the 2000 iteration\n",
      "this is epoch number 3\n",
      "this is the 0 iteration\n",
      "loss: 16.821 accuracy: 94.100\n",
      "this is the 1000 iteration\n",
      "loss: 23.926 accuracy: 93.800\n",
      "this is the 2000 iteration\n",
      "this is epoch number 4\n",
      "this is the 0 iteration\n",
      "loss: 15.354 accuracy: 94.800\n",
      "this is the 1000 iteration\n",
      "loss: 14.130 accuracy: 94.900\n",
      "this is the 2000 iteration\n",
      "this is epoch number 5\n",
      "this is the 0 iteration\n",
      "loss: 14.101 accuracy: 95.500\n",
      "this is the 1000 iteration\n",
      "loss: 12.888 accuracy: 95.700\n",
      "this is the 2000 iteration\n",
      "this is epoch number 6\n",
      "this is the 0 iteration\n",
      "loss: 13.117 accuracy: 95.500\n",
      "this is the 1000 iteration\n",
      "loss: 11.848 accuracy: 95.850\n",
      "this is the 2000 iteration\n",
      "this is epoch number 7\n",
      "this is the 0 iteration\n",
      "loss: 12.205 accuracy: 96.000\n",
      "this is the 1000 iteration\n",
      "loss: 10.911 accuracy: 96.150\n",
      "this is the 2000 iteration\n"
     ]
    }
   ],
   "source": [
    "model5.train()\n",
    "for epoch in range(epochs_5):\n",
    "    running_loss = 0 \n",
    "    predicted_list = []\n",
    "    labels_list = []\n",
    "    print(f'this is epoch number {epoch}')\n",
    "    for i, (input1,input2, label) in enumerate(e_soft_training):\n",
    "        optimiser5.zero_grad()\n",
    "        labels_list.append(label)\n",
    "        label = torch.tensor(label).view(-1)\n",
    "        if (i % 1000 == 0):\n",
    "            print(f'this is the {i} iteration')\n",
    "        outputs = model5(input1, input2)\n",
    "        loss = criterion5(outputs, label)\n",
    "        loss.backward()\n",
    "        optimiser5.step()\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        predicted_list.append(predicted.item())\n",
    "        if i % 1000 == 999:   \n",
    "            print('loss: %.3f accuracy: %.3f' %(running_loss/10, 100 * accuracy_score(labels_list, predicted_list)))\n",
    "            running_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model5.eval()\n",
    "loss = 0 \n",
    "labels_list = []\n",
    "predicted_list = []\n",
    "with torch.no_grad():\n",
    "    for i, (input1,input2, label) in enumerate(e_soft_testing):\n",
    "        label = torch.tensor(label).view(-1)\n",
    "        labels_list.append(label.item())\n",
    "        outputs = model5(input1, input2)\n",
    "        loss += criterion5(outputs, label).item()\n",
    "        predicted = outputs.argmax(dim = 1 , keepdim = True)\n",
    "        predicted_list.append(predicted.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the model accuracy is 0.969187675070028\n"
     ]
    }
   ],
   "source": [
    "print(f'the model accuracy is {accuracy_score(labels_list, predicted_list)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "58585ea05f9f6f2b628a57adeb9d9d9b0d3552877a9b4072f333eacdc19945fc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
