{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Late merge with hard parameters ##"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# imports\n","import os\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import  Dataset\n","from PIL import Image\n","from torchvision import transforms\n","import random\n","from sklearn.metrics import accuracy_score"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["class lmerge_dataloader(Dataset):\n","    def __init__(self, path , train):\n","        self.path = path\n","        self.all_classes = ['NotSnow','Snow']\n","        self.class_indexes = {cls: idx for idx, cls in enumerate(self.all_classes)}\n","        self.dataset = self.data_lister(train)\n","        self.length = len(self.dataset)\n","    def data_lister(self, train): \n","        data_list = []\n","        for class_name in self.all_classes:\n","            all_class_folders =os.path.join(self.path, class_name)\n","            for fold in os.listdir(all_class_folders):\n","                if fold == \".DS_Store\":\n","                    continue\n","                sample_path_n_class = os.path.join(all_class_folders, fold)\n","                sample = (sample_path_n_class, self.class_indexes[class_name])\n","                data_list.append(sample)\n","        random.shuffle(data_list)\n","        if train:\n","            return data_list[:int(0.8*len(data_list))]\n","        else:\n","            return data_list[int(0.8*len(data_list)):]\n","    def __len__(self):\n","        return self.length\n","    \n","    def __getitem__(self, index):\n","        sample_path, sample_class = self.dataset[index]\n","        pic1 = transforms.ToTensor()(Image.open(os.path.join(sample_path, '0.png')).convert('L')) # image 1 in tensor\n","        pic2 = transforms.ToTensor()(Image.open(os.path.join(sample_path, '1.png')).convert('L')) # image 2 in tensor\n","        transform = transforms.Compose([\n","            transforms.Resize((224, 224)),\n","        ])\n","        pic1 = transform(pic1)\n","        pic2 = transform(pic2)\n","        \n","        return pic1 , pic2, sample_class"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["late_hard_training = lmerge_dataloader('./dataset/', True)\n","late_hard_testing = lmerge_dataloader('./dataset/', False)"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["2518\n","1049\n"]}],"source":["print(len(os.listdir(\"./dataset/./NotSnow/\")))\n","print(len(os.listdir(\"./dataset/./Snow/\")))"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([1, 224, 224])\n","torch.Size([1, 224, 224])\n","0\n"]}],"source":["sample = late_hard_training[1311]\n","print(sample[0].shape)\n","print(sample[1].shape)\n","print(sample[2])"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["class late_merge_NN(nn.Module):\n","    def __init__(self):\n","        super(late_merge_NN, self).__init__()\n","        self.convolve1 = nn.Conv2d(1, 2, 1)\n","        self.convolve2 = nn.Conv2d(2, 4, 1)\n","        self.pool = nn.MaxPool2d(kernel_size=4, stride=5)\n","        self.convolve12 = nn.Conv2d(1, 2, 1)\n","        self.convolve22 = nn.Conv2d(2, 4, 1)\n","        self.pool2 = nn.MaxPool2d(kernel_size=4, stride=5)\n","        self.full1 = nn.Linear(648, 2)\n","\n","    def forward(self, x1, x2):\n","        x1 = self.convolve1(x1)\n","        x1 = self.pool(x1)\n","        x1 = self.convolve2(x1)\n","        x1 = self.pool(x1)\n","        x1 = x1.view(-1, 324)\n","        \n","        x2 = self.convolve12(x2)\n","        x2 = self.pool2(x2)\n","        x2 = self.convolve22(x2)\n","        x2 = self.pool2(x2)\n","        x2 = x2.view(-1, 324)\n","\n","        x = torch.cat((x1, x2), dim=1)\n","        x = self.full1(x)\n","        return x\n"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["# hyper parameters\n","learning_rate_2= 0.001\n","epochs_2 = 5"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["# training the neural net with the stacking dataset\n","model2 = late_merge_NN()\n","criterion2 = nn.CrossEntropyLoss()\n","optimiser2 = optim.Adam(model2.parameters(), lr = learning_rate_2)"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["the total number of parameters in this model are 1330\n"]}],"source":["# model params\n","total_params = sum(p.numel() for p in model2.parameters())\n","print(f'the total number of parameters in this model are {total_params}')"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["this is epoch number 0\n","this is the 0 iteration\n","loss: 47.122 accuracy: 73.600\n","this is the 1000 iteration\n","loss: 30.090 accuracy: 79.750\n","this is the 2000 iteration\n","this is epoch number 1\n","this is the 0 iteration\n","loss: 28.197 accuracy: 87.900\n","this is the 1000 iteration\n","loss: 24.406 accuracy: 89.050\n","this is the 2000 iteration\n","this is epoch number 2\n","this is the 0 iteration\n","loss: 25.079 accuracy: 89.300\n","this is the 1000 iteration\n","loss: 21.728 accuracy: 90.400\n","this is the 2000 iteration\n","this is epoch number 3\n","this is the 0 iteration\n","loss: 22.926 accuracy: 90.900\n","this is the 1000 iteration\n","loss: 19.719 accuracy: 91.800\n","this is the 2000 iteration\n","this is epoch number 4\n","this is the 0 iteration\n","loss: 21.081 accuracy: 92.200\n","this is the 1000 iteration\n","loss: 18.008 accuracy: 92.900\n","this is the 2000 iteration\n"]}],"source":["model2.train()\n","for epoch in range(epochs_2):\n","    running_loss = 0 \n","    predicted_list = []\n","    labels_list = []\n","    print(f'this is epoch number {epoch}')\n","    for i, (input1,input2, label) in enumerate(late_hard_training):\n","        labels_list.append(label)\n","        optimiser2.zero_grad()\n","        label = torch.tensor(label).view(-1)\n","        if (i % 1000 == 0):\n","            print(f'this is the {i} iteration')\n","        outputs = model2(input1, input2)\n","        loss = criterion2(outputs, label)\n","        loss.backward()\n","        optimiser2.step()\n","        _, predicted = torch.max(outputs.data, 1)\n","        predicted_list.append(predicted.item())\n","        running_loss += loss.item()\n","        if i % 1000 == 999:   \n","            print('loss: %.3f accuracy: %.3f' %(running_loss / 10, 100 *accuracy_score(labels_list, predicted_list)))\n","            running_loss = 0.\n","           "]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/var/folders/l8/nqt3x5yn28z6g3mdkkcd_w940000gn/T/ipykernel_32148/2927117641.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  label = torch.tensor(label).view(-1)\n"]},{"name":"stdout","output_type":"stream","text":["this is the 0 iteration\n"]}],"source":["model2.eval()\n","loss = 0 \n","correct = 0\n","total = 0\n","count = 0\n","predicted_list = []\n","labels_list = []\n","with torch.no_grad():\n","    for i, (input1,input2, label) in enumerate(late_hard_testing):\n","        label = torch.tensor(label)\n","        label = torch.tensor(label).view(-1)\n","        labels_list.append(label.item())\n","        if (i % 1000 == 0):\n","            print(f'this is the {i} iteration')\n","        outputs = model2(input1, input2)\n","        loss += criterion2(outputs, label).item()\n","        predicted = outputs.argmax(dim = 1 , keepdim = True)\n","        predicted_list.append(predicted.item())\n"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["the model accuracy is 0.9411764705882353\n"]}],"source":["print(f'the model accuracy is {accuracy_score(labels_list, predicted_list)}')"]}],"metadata":{"kernelspec":{"display_name":"ML","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.8"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"58585ea05f9f6f2b628a57adeb9d9d9b0d3552877a9b4072f333eacdc19945fc"}}},"nbformat":4,"nbformat_minor":2}
