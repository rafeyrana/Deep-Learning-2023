{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Stacking Model ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from sklearn.metrics import accuracy_score\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class stacking_dataloader(Dataset):\n",
    "    def __init__(self, path , train= True):\n",
    "        self.path = path\n",
    "        self.all_classes = ['NotSnow','Snow']\n",
    "        self.class_indexes = {cls: idx for idx, cls in enumerate(self.all_classes)}\n",
    "        self.dataset = self.data_lister(train)\n",
    "        self.length = len(self.dataset)\n",
    "        self.train_test = train\n",
    "    def data_lister(self, train):\n",
    "        data_list = []\n",
    "        for class_name in self.all_classes:\n",
    "            all_class_folders =os.path.join(self.path, class_name)\n",
    "            for fold in os.listdir(all_class_folders):\n",
    "                if fold == \".DS_Store\":\n",
    "                    continue\n",
    "                sample_path_n_class = os.path.join(all_class_folders, fold)\n",
    "                sample = (sample_path_n_class, self.class_indexes[class_name])\n",
    "                data_list.append(sample)\n",
    "        random.shuffle(data_list)\n",
    "        \n",
    "        if train:\n",
    "            return data_list[:int(0.8*len(data_list))]\n",
    "        else:\n",
    "            return data_list[int(0.8*len(data_list)):]\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        sample_path, sample_class = self.dataset[index]\n",
    "        pic1 = transforms.ToTensor()(Image.open(os.path.join(sample_path, '0.png')).convert('L')) # image 1 in tensor\n",
    "        pic2 = transforms.ToTensor()(Image.open(os.path.join(sample_path, '1.png')).convert('L')) # image 2 in tensor\n",
    "        sample = torch.cat((pic1, pic2), dim=0).unsqueeze(0)\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "        \n",
    "        ])\n",
    "        sample = transform(sample)\n",
    "        return sample , sample_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking_training = stacking_dataloader('./dataset/', True)\n",
    "stacking_testing = stacking_dataloader('./dataset/', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the object returned is a tuple containing the tensor and the class label\n",
      "the shape of each tensor in this case is torch.Size([1, 2, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "print(f'the object returned is a tuple containing the tensor and the class label')\n",
    "print(f'the shape of each tensor in this case is {stacking_training[0][0].shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class stacking_CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(stacking_CNN, self).__init__()\n",
    "        self.conv1  = nn.Conv2d(2,4, 2,stride= 1)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        self.conv2 = nn.Conv2d(4, 5, 2, padding=1)\n",
    "        self.conv3 = nn.Conv2d(5, 6, 3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(6, 7, 2, padding=1)\n",
    "        self.conv5 = nn.Conv2d(7, 4, 3, padding=1)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(4, 2)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = self.conv4(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = self.conv5(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = stacking_CNN()\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimiser = optim.Adam(model.parameters(), lr = learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the total number of parameters in this model are 838\n"
     ]
    }
   ],
   "source": [
    "# model params\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f'the total number of parameters in this model are {total_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is epoch number 0\n",
      "this is the 0 iteration\n",
      " loss: 60.980 accuracy: 71.000\n",
      "this is the 1000 iteration\n",
      " loss: 60.878 accuracy: 70.100\n",
      "this is the 2000 iteration\n",
      "this is epoch number 1\n",
      "this is the 0 iteration\n",
      " loss: 54.342 accuracy: 71.000\n",
      "this is the 1000 iteration\n",
      " loss: 51.932 accuracy: 70.050\n",
      "this is the 2000 iteration\n",
      "this is epoch number 2\n",
      "this is the 0 iteration\n",
      " loss: 39.709 accuracy: 80.700\n",
      "this is the 1000 iteration\n",
      " loss: 33.594 accuracy: 82.300\n",
      "this is the 2000 iteration\n",
      "this is epoch number 3\n",
      "this is the 0 iteration\n",
      " loss: 30.106 accuracy: 86.200\n",
      "this is the 1000 iteration\n",
      " loss: 28.594 accuracy: 86.600\n",
      "this is the 2000 iteration\n",
      "this is epoch number 4\n",
      "this is the 0 iteration\n",
      " loss: 27.403 accuracy: 88.700\n",
      "this is the 1000 iteration\n",
      " loss: 24.787 accuracy: 89.000\n",
      "this is the 2000 iteration\n",
      "this is epoch number 5\n",
      "this is the 0 iteration\n",
      " loss: 24.570 accuracy: 89.800\n",
      "this is the 1000 iteration\n",
      " loss: 21.554 accuracy: 90.400\n",
      "this is the 2000 iteration\n",
      "this is epoch number 6\n",
      "this is the 0 iteration\n",
      " loss: 22.089 accuracy: 91.400\n",
      "this is the 1000 iteration\n",
      " loss: 19.597 accuracy: 92.150\n",
      "this is the 2000 iteration\n",
      "this is epoch number 7\n",
      "this is the 0 iteration\n",
      " loss: 20.465 accuracy: 91.900\n",
      "this is the 1000 iteration\n",
      " loss: 18.352 accuracy: 92.850\n",
      "this is the 2000 iteration\n",
      "this is epoch number 8\n",
      "this is the 0 iteration\n",
      " loss: 19.334 accuracy: 92.900\n",
      "this is the 1000 iteration\n",
      " loss: 17.457 accuracy: 93.350\n",
      "this is the 2000 iteration\n",
      "this is epoch number 9\n",
      "this is the 0 iteration\n",
      " loss: 18.298 accuracy: 93.300\n",
      "this is the 1000 iteration\n",
      " loss: 16.849 accuracy: 93.650\n",
      "this is the 2000 iteration\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    runnning_loss = 0 \n",
    "    predicted_list = []\n",
    "    labels_list = []\n",
    "    print(f'this is epoch number {epoch}')\n",
    "    for i, (input, label) in enumerate(stacking_training):\n",
    "        optimiser.zero_grad()\n",
    "        labels_list.append(label)\n",
    "        label = torch.tensor(label).view(-1)\n",
    "        if (i % 1000 == 0):\n",
    "            print(f'this is the {i} iteration')\n",
    "        outputs = model(input)\n",
    "        label = F.one_hot(label, num_classes=2).float()\n",
    "        loss = criterion(outputs, label)\n",
    "        loss.backward()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        predicted_list.append(predicted.item())\n",
    "        runnning_loss += loss.item()\n",
    "        optimiser.step()\n",
    "        if i % 1000 == 999:   \n",
    "            print(' loss: %.3f accuracy: %.3f' %( runnning_loss / 10, 100 * accuracy_score(labels_list, predicted_list)))\n",
    "            runnning_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "loss = 0 \n",
    "correct = 0\n",
    "labels_list = []\n",
    "predicted_list = []\n",
    "total = 0\n",
    "count = 0\n",
    "with torch.no_grad():\n",
    "    for i, (input, label) in enumerate(stacking_testing):\n",
    "        label = torch.tensor(label)\n",
    "        labels_list.append(label.item())\n",
    "        label= label.view(-1)\n",
    "        label = F.one_hot(label, num_classes=2).float()\n",
    "        outputs = model(input)\n",
    "        loss += criterion(outputs, label).item()\n",
    "        predicted = outputs.argmax(dim = 1,keepdim = True)\n",
    "        predicted_list.append(predicted.item())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the model accuracy in this case is 0.9523809523809523\n"
     ]
    }
   ],
   "source": [
    "print(f'the model accuracy in this case is {accuracy_score(labels_list, predicted_list)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "58585ea05f9f6f2b628a57adeb9d9d9b0d3552877a9b4072f333eacdc19945fc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
