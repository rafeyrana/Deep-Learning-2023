{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Late merge with soft parameters ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import random\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class hard_dataloader(Dataset):\n",
    "    def __init__(self, data_dir , train):\n",
    "        self.data_dir = data_dir\n",
    "        self.all_classes = ['NotSnow','Snow']\n",
    "        self.class_indexes = {cls: idx for idx, cls in enumerate(self.all_classes)}\n",
    "        self.dataset = self.dataset_maker(train)\n",
    "        self.length = len(self.dataset)\n",
    "    def dataset_maker(self, train): # this will compile all the folder paths and the corresponding classes in a tuple to be stored in the class\n",
    "        data_list = []\n",
    "        for class_name in self.all_classes:\n",
    "            all_class_folders =os.path.join(self.data_dir, class_name)\n",
    "            for fold in os.listdir(all_class_folders):\n",
    "                if fold == \".DS_Store\":\n",
    "                    continue\n",
    "                sample_path_n_class = os.path.join(all_class_folders, fold)\n",
    "                sample = (sample_path_n_class, self.class_indexes[class_name])\n",
    "                data_list.append(sample)\n",
    "        random.shuffle(data_list)\n",
    "        if train:\n",
    "            return data_list[:int(0.8*len(data_list))]\n",
    "        else:\n",
    "            return data_list[int(0.8*len(data_list)):]\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        sample_path, sample_class = self.dataset[index]\n",
    "        pic1 = transforms.ToTensor()(Image.open(os.path.join(sample_path, '0.png')).convert('L')) # image 1 in tensor\n",
    "        pic2 = transforms.ToTensor()(Image.open(os.path.join(sample_path, '1.png')).convert('L')) # image 2 in tensor\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "        ])\n",
    "        pic1 = transform(pic1)\n",
    "        pic2 = transform(pic2)\n",
    "        return pic1.unsqueeze(0) , pic2.unsqueeze(0), sample_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_soft_training = hard_dataloader(\"./dataset/\", True)\n",
    "e_soft_testing = hard_dataloader(\"./dataset/\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "714\n",
      "2852\n"
     ]
    }
   ],
   "source": [
    "print(len(e_soft_testing))\n",
    "print(len(e_soft_training))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 224, 224])\n",
      "torch.Size([1, 1, 224, 224])\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "sample3 = e_soft_training[242]\n",
    "print(sample3[0].shape)\n",
    "print(sample3[1].shape)\n",
    "print(sample3[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class late_soft_cnn(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(late_soft_cnn, self).__init__()\n",
    "        self.conv1 = nn. Conv2d(1, 4, kernel_size=2, stride=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn. Conv2d(4, 6, kernel_size=4, stride=3)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=5, stride=5)\n",
    "        # self.conv4 = nn. Conv2d(4, 6, kernel_size=3, stride=1)\n",
    "        # self.pool4 = nn.MaxPool2d(kernel_size=5, stride=1)\n",
    "        self.fc1 = nn.Linear (588, 2)\n",
    "        \n",
    "    def forward (self, x1,x2):\n",
    "        x1 = F.relu(self.conv1(x1))\n",
    "        x1 = self.pool(x1)\n",
    "        x2 = F.relu(self.conv1(x2))\n",
    "        x2 = self.pool(x2)\n",
    "        x1 = F.relu(self.conv2(x1))\n",
    "        x1 = self.pool2(x1)\n",
    "        x2 = F.relu(self.conv2(x2))\n",
    "        x2 = self.pool2(x2)\n",
    "        # x1 = F.relu(self.conv4(x1))\n",
    "        # x2 = F.relu(self.conv4(x2))\n",
    "        # x1 = self.pool4(x1)\n",
    "        # x2 = self.pool4(x2)\n",
    "        x= torch.cat((x1, x2), dim=1)\n",
    "        x=torch.flatten (x, 1)\n",
    "        x = self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper parameters\n",
    "learning_rate_4= 0.001\n",
    "epochs_4 = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training the neural net with the stacking dataset\n",
    "model4 = late_soft_cnn()\n",
    "criterion4 = nn.CrossEntropyLoss()\n",
    "optimiser4 = optim.Adam(model4.parameters(), lr = learning_rate_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the total number of parameters in this model are 1588\n"
     ]
    }
   ],
   "source": [
    "# model params\n",
    "total_params = sum(p.numel() for p in model4.parameters())\n",
    "print(f'the total number of parameters in this model are {total_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is epoch number 0\n",
      "this is the 0 iteration\n",
      " loss: 37.114 accuracy: 82.400\n",
      "this is the 1000 iteration\n",
      " loss: 26.182 accuracy: 85.900\n",
      "this is the 2000 iteration\n",
      "this is epoch number 1\n",
      "this is the 0 iteration\n",
      " loss: 22.568 accuracy: 92.000\n",
      "this is the 1000 iteration\n",
      " loss: 19.497 accuracy: 92.200\n",
      "this is the 2000 iteration\n",
      "this is epoch number 2\n",
      "this is the 0 iteration\n",
      " loss: 17.292 accuracy: 93.700\n",
      "this is the 1000 iteration\n",
      " loss: 15.931 accuracy: 93.600\n",
      "this is the 2000 iteration\n",
      "this is epoch number 3\n",
      "this is the 0 iteration\n",
      " loss: 14.869 accuracy: 94.300\n",
      "this is the 1000 iteration\n",
      " loss: 14.237 accuracy: 94.550\n",
      "this is the 2000 iteration\n",
      "this is epoch number 4\n",
      "this is the 0 iteration\n",
      " loss: 13.448 accuracy: 95.000\n",
      "this is the 1000 iteration\n",
      " loss: 13.176 accuracy: 95.400\n",
      "this is the 2000 iteration\n"
     ]
    }
   ],
   "source": [
    "model4.train()\n",
    "for epoch in range(epochs_4):\n",
    "    running_loss = 0 \n",
    "    labels_list = []\n",
    "    predicted_list = []\n",
    "    print(f'this is epoch number {epoch}')\n",
    "    for i, (input1,input2, label) in enumerate(e_soft_training):\n",
    "        optimiser4.zero_grad()\n",
    "        labels_list.append(label)\n",
    "        label = torch.tensor(label).view(-1)\n",
    "        if (i % 1000 == 0):\n",
    "            print(f'this is the {i} iteration')\n",
    "        outputs = model4(input1, input2)\n",
    "        loss = criterion4(outputs, label)\n",
    "        loss.backward()\n",
    "        optimiser4.step()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        predicted_list.append(predicted.item())\n",
    "        running_loss += loss.item()\n",
    "        if i % 1000 == 999:   \n",
    "            print(' loss: %.3f accuracy: %.3f' %(running_loss / 10,  100 *accuracy_score(labels_list, predicted_list)))\n",
    "            running_loss = 0\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4.eval()\n",
    "loss = 0 \n",
    "labels_list = []\n",
    "predicted_list = []\n",
    "with torch.no_grad():\n",
    "    for i, (input1,input2, label) in enumerate(e_soft_testing):\n",
    "        label = torch.tensor(label).view(-1)\n",
    "        labels_list.append(label.item())\n",
    "        outputs = model4(input1, input2)\n",
    "        loss += criterion4(outputs, label).item()\n",
    "        predicted = outputs.argmax(dim = 1 , keepdim = True)\n",
    "        predicted_list.append(predicted.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the model accuracy is 0.969187675070028\n"
     ]
    }
   ],
   "source": [
    "print(f'the model accuracy is {accuracy_score(labels_list, predicted_list)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "58585ea05f9f6f2b628a57adeb9d9d9b0d3552877a9b4072f333eacdc19945fc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
