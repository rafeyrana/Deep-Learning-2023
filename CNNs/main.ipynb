{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Assignment 2 #"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### using pytorch models to identify snow vs no snow in images, the goal of this assignment is to not only achieve higher accuracy but to also keep the number of parameters to a minimum so that results are computed as fast as possible ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "from torchvision import transforms"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloaders ##"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloader for stacking ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class stacking_dataloader(Dataset):\n",
    "    def __init__(self, data_dir ):\n",
    "        self.data_dir = data_dir\n",
    "        self.all_classes = ['NotSnow','Snow']\n",
    "        self.class_indexes = {cls: idx for idx, cls in enumerate(self.all_classes)}\n",
    "        self.dataset = self.dataset_maker()\n",
    "        self.length = len(self.dataset)\n",
    "    def dataset_maker(self): # this will compile all the folder paths and the corresponding classes in a tuple to be stored in the class\n",
    "        data_list = []\n",
    "        for class_name in self.all_classes:\n",
    "            all_class_folders =os.path.join(self.data_dir, class_name)\n",
    "            for fold in os.listdir(all_class_folders):\n",
    "                sample_path_n_class = os.path.join(all_class_folders, fold)\n",
    "                sample = (sample_path_n_class, self.class_indexes[class_name])\n",
    "                data_list.append(sample)\n",
    "        return data_list\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        sample_path, sample_class = self.dataset[index]\n",
    "        # this path will have the final two images which will have to be processed individually and returned as a stacked vector for the stacking model input which we will have to consider in this case\n",
    "        # all images in the dataset are named 0.png or 1.png in this case which we will hardcode in this class       \n",
    "        pic1 = transforms.ToTensor()(Image.open(os.path.join(sample_path, '0.png'))) # image 1 in tensor\n",
    "        pic2 = transforms.ToTensor()(Image.open(os.path.join(sample_path, '0.png'))) # image 2 in tensor\n",
    "        sample = torch.stack([pic1, pic2], dim = 0) # dim = 0 because we have to stack them on top of each other in this case\n",
    "        # do we need to normalise this ?\n",
    "        #defining a resizing and normalisation transformation to \n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.Normalize(mean=[0.485], std=[0.5]) # using dummy values in this case for the greyscale normalisation\n",
    "        ])\n",
    "\n",
    "        # Apply the transformation pipeline to the input sample\n",
    "        sample = transform(sample)\n",
    "        return sample ,  sample_class"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models ##"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking Model ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking_dataset = stacking_dataloader('./dataset/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the total dataset size is 3568\n",
      "the object returned is a tuple containing the tensor and the class label\n",
      "the shape of each tensor in this case is torch.Size([2, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "print(f\"the total dataset size is {len(stacking_dataset)}\")\n",
    "print(f'the object returned is a tuple containing the tensor and the class label')\n",
    "print(f'the shape of each tensor in this case is {stacking_dataset[1][0].shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "58585ea05f9f6f2b628a57adeb9d9d9b0d3552877a9b4072f333eacdc19945fc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
