{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification task using late merge with hard paramter sharing and adaptive learning rates #"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in this model wwe will be using adaptive learning rates and reduce the learning rate as the model trains on a time based decay strategy using a learning rate scheduler the network architecture will be a late merge with hard parameter sharing as in my experience it is the best for this tak, i also tried soft paramter sharing wiht eraly merge but that was not as accurate in this case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import  Dataset\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import random\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch.optim.lr_scheduler as lr_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class lmerge_dataloader(Dataset):\n",
    "    def __init__(self, path , train):\n",
    "        self.path = path\n",
    "        self.all_classes = ['NotSnow','Snow']\n",
    "        self.class_indexes = {cls: idx for idx, cls in enumerate(self.all_classes)}\n",
    "        self.dataset = self.data_lister(train)\n",
    "        self.length = len(self.dataset)\n",
    "    def data_lister(self, train): \n",
    "        data_list = []\n",
    "        for class_name in self.all_classes:\n",
    "            all_class_folders =os.path.join(self.path, class_name)\n",
    "            for fold in os.listdir(all_class_folders):\n",
    "                if fold == \".DS_Store\":\n",
    "                    continue\n",
    "                sample_path_n_class = os.path.join(all_class_folders, fold)\n",
    "                sample = (sample_path_n_class, self.class_indexes[class_name])\n",
    "                data_list.append(sample)\n",
    "        random.shuffle(data_list)\n",
    "        if train:\n",
    "            return data_list[:int(0.8*len(data_list))]\n",
    "        else:\n",
    "            return data_list[int(0.8*len(data_list)):]\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        sample_path, sample_class = self.dataset[index]\n",
    "      \n",
    "        pic1 = transforms.ToTensor()(Image.open(os.path.join(sample_path, '0.png')).convert('L')) # image 1 in tensor\n",
    "        pic2 = transforms.ToTensor()(Image.open(os.path.join(sample_path, '1.png')).convert('L')) # image 2 in tensor\n",
    "      \n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "        ])\n",
    "        pic1 = transform(pic1)\n",
    "        pic2 = transform(pic2)\n",
    "        \n",
    "        return pic1 , pic2, sample_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaptive_training = lmerge_dataloader('./dataset/', True)\n",
    "adaptive_testing = lmerge_dataloader('./dataset/', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "sample8 = adaptive_training[1311]\n",
    "print(sample8[0].shape)\n",
    "print(sample8[1].shape)\n",
    "print(sample8[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class late_merge_NN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(late_merge_NN, self).__init__()\n",
    "        self.convoluton1 = nn.Conv2d(1, 2, 1)\n",
    "        self.convoluton2 = nn.Conv2d(2, 4, 1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=4, stride=5)\n",
    "        self.convoluton12 = nn.Conv2d(1, 2, 1)\n",
    "        self.convoluton22 = nn.Conv2d(2, 4, 1)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=4, stride=5)\n",
    "        self.full1 = nn.Linear(648, 2)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.convoluton1(x1)\n",
    "        x1 = self.pool(x1)\n",
    "        x1 = self.convoluton2(x1)\n",
    "        x1 = self.pool(x1)\n",
    "        x1 = x1.view(-1, 324)\n",
    "        \n",
    "        x2 = self.convoluton12(x2)\n",
    "        x2 = self.pool2(x2)\n",
    "        x2 = self.convoluton22(x2)\n",
    "        x2 = self.pool2(x2)\n",
    "        x2 = x2.view(-1, 324)\n",
    "\n",
    "        x = torch.cat((x1, x2), dim=1)\n",
    "        x = self.full1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper parameters\n",
    "learning_rate_8= 0.01\n",
    "epochs_8 = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training the neural net with the stacking dataset\n",
    "model8 = late_merge_NN()\n",
    "criterion8 = nn.CrossEntropyLoss()\n",
    "optimiser8 = optim.Adam(model8.parameters(), lr = learning_rate_8)\n",
    "scheduler = lr_scheduler.StepLR(optimiser8, step_size=1, gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the total number of parameters in this model are 1330\n"
     ]
    }
   ],
   "source": [
    "# model params\n",
    "total_params = sum(p.numel() for p in model8.parameters())\n",
    "print(f'the total number of parameters in this model are {total_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is epoch number 0\n",
      "this is the 0 iteration\n",
      "loss: 48.118 accuracy: 82.100\n",
      "this is the 1000 iteration\n",
      "loss: 28.420 accuracy: 85.750\n",
      "this is the 2000 iteration\n",
      "this is epoch number 1\n",
      "this is the 0 iteration\n",
      "loss: 23.916 accuracy: 90.800\n",
      "this is the 1000 iteration\n",
      "loss: 22.959 accuracy: 91.300\n",
      "this is the 2000 iteration\n",
      "this is epoch number 2\n",
      "this is the 0 iteration\n",
      "loss: 18.408 accuracy: 93.500\n",
      "this is the 1000 iteration\n",
      "loss: 17.379 accuracy: 93.850\n",
      "this is the 2000 iteration\n"
     ]
    }
   ],
   "source": [
    "model8.train()\n",
    "for epoch in range(epochs_8):\n",
    "    running_loss = 0 \n",
    "    predicted_list = []\n",
    "    labels_list = []\n",
    "    print(f'this is epoch number {epoch}')\n",
    "    for i, (input1,input2, label) in enumerate(adaptive_training):\n",
    "        optimiser8.zero_grad()\n",
    "        labels_list.append(label)\n",
    "        label = torch.tensor(label).view(-1)\n",
    "        if (i % 1000 == 0):\n",
    "            print(f'this is the {i} iteration')\n",
    "        outputs = model8(input1, input2)\n",
    "        loss = criterion8(outputs, label)\n",
    "        loss.backward()\n",
    "        running_loss += loss.item()\n",
    "        optimiser8.step()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        predicted_list.append(predicted.item())\n",
    "        if i % 1000 == 999:   \n",
    "            print('loss: %.3f accuracy: %.3f' %(running_loss / 10, 100 * accuracy_score(labels_list, predicted_list)))\n",
    "            running_loss = 0\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l8/nqt3x5yn28z6g3mdkkcd_w940000gn/T/ipykernel_29060/4184472181.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  label = torch.tensor(label).view(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is the 0 iteration\n"
     ]
    }
   ],
   "source": [
    "model8.eval()\n",
    "loss = 0 \n",
    "predicted_list = []\n",
    "labels_list = []\n",
    "with torch.no_grad():\n",
    "    for i, (input1,input2, label) in enumerate(adaptive_testing):\n",
    "        label = torch.tensor(label)\n",
    "        label = torch.tensor(label).view(-1)\n",
    "        labels_list.append(label.item())\n",
    "        if (i % 1000 == 0):\n",
    "            print(f'this is the {i} iteration')\n",
    "        outputs = model8(input1, input2)\n",
    "        loss += criterion8(outputs, label).item()\n",
    "        predicted = outputs.argmax(dim = 1 , keepdim = True)\n",
    "        predicted_list.append(predicted.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the model accuracy is 0.9425770308123249\n"
     ]
    }
   ],
   "source": [
    "print(f'the model accuracy is {accuracy_score(labels_list, predicted_list)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "58585ea05f9f6f2b628a57adeb9d9d9b0d3552877a9b4072f333eacdc19945fc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
